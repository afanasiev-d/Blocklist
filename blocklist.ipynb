{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4697e299-41df-43ec-9cc7-8be9b267d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import base58\n",
    "import hashlib\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "import warnings\n",
    "import gc\n",
    "import argparse\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "import hashlib\n",
    "import os\n",
    "import psutil\n",
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "\n",
    "# Set up logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)  # Set the logging level\n",
    "\n",
    "# Remove any default handlers associated with the logger\n",
    "logger.handlers = []\n",
    "\n",
    "# Create a file handler\n",
    "handler = logging.FileHandler('worklog.log', encoding='utf-8')\n",
    "# Create a rotating file handler\n",
    "handler.setLevel(logging.DEBUG)  # Set the handler level\n",
    "\n",
    "# Create a logging format\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Add the file handler to the logger\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Disable propagation to avoid printing to the console\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ce14c988-156c-49f1-80e9-667a4d512ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "TRON_NODE_URL = \"https://trx-rpc.transatron.io\"\n",
    "\n",
    "\n",
    "# Кеш для адрес\n",
    "address_cache = {}\n",
    "\n",
    "def hex_to_base58(hex_address):\n",
    "    if hex_address in address_cache:\n",
    "        return address_cache[hex_address]\n",
    "    if not hex_address.startswith(\"41\"):\n",
    "        raise ValueError(\"Invalid Tron address: Must start with '41'\")\n",
    "\n",
    "    address_bytes = bytes.fromhex(hex_address)\n",
    "    checksum = hashlib.sha256(hashlib.sha256(address_bytes).digest()).digest()[:4]\n",
    "    address_with_checksum = address_bytes + checksum\n",
    "    base58_address = base58.b58encode(address_with_checksum).decode()\n",
    "    address_cache[hex_address] = base58_address\n",
    "    return base58_address\n",
    "\n",
    "\n",
    "def hex_to_tron_address(hex_address):\n",
    "    \"\"\"\n",
    "    Convert a 20-byte hex address to a TRON address with the '41' prefix.\n",
    "    \"\"\"\n",
    "    return \"41\" + hex_address[-40:]\n",
    "\n",
    "def get_block_transactions(block_number):\n",
    "    \"\"\"\n",
    "    Fetch and process transactions for a specific block using the TRON Full Node.\n",
    "    \"\"\"\n",
    "    url = f\"{TRON_NODE_URL}/wallet/gettransactioninfobyblocknum\"\n",
    "    \n",
    "    # Send request to get transaction info for the block\n",
    "    response = requests.post(url, json={\"num\": block_number})\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Parse the response JSON\n",
    "    block_data = response.json()\n",
    "\n",
    "    # Add block timestamp to each transaction\n",
    "    for tx in block_data:\n",
    "        # Attach block timestamp to each transaction\n",
    "        tx[\"block_timestamp\"] = block_data[0][\"blockTimeStamp\"]  # Assuming all transactions share the same timestamp in the block\n",
    "        tx[\"block_number\"] = block_number\n",
    "\n",
    "    return block_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab31df76-4a5c-43d2-886e-69b15133f4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_successful_transactions(transactions):\n",
    "    return [\n",
    "        tx for tx in transactions\n",
    "        if tx.get(\"receipt\", {}).get(\"result\") == \"SUCCESS\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6655df10-7163-4725-910c-e5fef372e5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions=get_block_transactions(57833080)\n",
    "successful_transactions=filter_successful_transactions(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f26f67b2-65ff-4305-8a28-e8b56bda7a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#successful_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3104051-3220-404c-a808-a71d037fd65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event Signatures\n",
    "ADDED_BLACKLIST_TOPIC = \"42e160154868087d6bfdc0ca23d96a1c1cfa32f1b72ba9ba27b69b98a0d819dc\"\n",
    "REMOVED_BLACKLIST_TOPIC = \"d7e9ec6e6ecd65492dce6bf513cd6867560d49544421d0783ddf06e76c24470c\"\n",
    "\n",
    "def filter_blacklist_transactions(transactions):\n",
    "    return [\n",
    "        tx for tx in transactions\n",
    "        if any(topic == ADDED_BLACKLIST_TOPIC or topic == REMOVED_BLACKLIST_TOPIC for topic in (tx.get(\"log\", [{}])[0].get(\"topics\", [])))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fe59b82b-dd02-4aab-93e0-efc6b6abd887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event Signatures\n",
    "ADDED_BLACKLIST_TOPIC = \"42e160154868087d6bfdc0ca23d96a1c1cfa32f1b72ba9ba27b69b98a0d819dc\"\n",
    "REMOVED_BLACKLIST_TOPIC = \"d7e9ec6e6ecd65492dce6bf513cd6867560d49544421d0783ddf06e76c24470c\"\n",
    "\n",
    "class BlockTransactionCache:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cache = {}\n",
    "\n",
    "    def get_filtered_transactions(self, block_number):\n",
    "        \"\"\"\n",
    "        Returns filtered transactions for a block from memory cache if available.\n",
    "        If not, fetches the transactions, filters for success, and stores them in the cache.\n",
    "        \"\"\"\n",
    "        if block_number in self.cache:\n",
    "            return self.cache[block_number]\n",
    "        \n",
    "        # Otherwise, fetch the block data and filter the transactions\n",
    "        filtered_transactions = self.filter_block_transactions(block_number)\n",
    "        \n",
    "        # Store the filtered transactions in memory cache\n",
    "        self.cache[block_number] = filtered_transactions\n",
    "        \n",
    "        return filtered_transactions\n",
    "\n",
    "    def filter_block_transactions(self, block_number):\n",
    "        \"\"\"\n",
    "        Fetches block transactions, filters them for success, \n",
    "        and then filters for Added/RemovedBlackList transactions.\n",
    "        \"\"\"\n",
    "        block_data = self.fetch_block_data(block_number)\n",
    "        successful_transactions = self.filter_successful_transactions(block_data)\n",
    "        filtered_transactions = self.filter_added_removed_blacklist(successful_transactions)\n",
    "        return filtered_transactions\n",
    "\n",
    "    def fetch_block_data(self, block_number):\n",
    "        \"\"\"\n",
    "        Fetch block data using your desired method (this is a placeholder).\n",
    "        \"\"\"\n",
    "        url = f\"{TRON_NODE_URL}/wallet/gettransactioninfobyblocknum\"\n",
    "        response = requests.post(url, json={\"num\": block_number})\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "    def filter_successful_transactions(self, transactions):\n",
    "        \"\"\"\n",
    "        Filter the transactions to include only successful ones (receipt.result == 'SUCCESS').\n",
    "        \"\"\"\n",
    "        return [\n",
    "            tx for tx in transactions\n",
    "            if tx.get(\"receipt\", {}).get(\"result\") == \"SUCCESS\"\n",
    "        ]\n",
    "\n",
    "    def filter_added_removed_blacklist(self, transactions):\n",
    "        \"\"\"\n",
    "        Filter the transactions to include only those related to\n",
    "        AddedBlackList and RemovedBlackList transactions.\n",
    "        \"\"\"\n",
    "        filtered = []\n",
    "        \n",
    "        # Loop through each transaction in the block data\n",
    "        for tx in transactions:\n",
    "            logs = tx.get('log', [])\n",
    "            \n",
    "            for log in logs:\n",
    "                if 'topics' in log:\n",
    "                    topics = log['topics']\n",
    "                    \n",
    "                    if len(topics) > 0 and (topics[0] == ADDED_BLACKLIST_TOPIC or topics[0] == REMOVED_BLACKLIST_TOPIC):\n",
    "                        filtered.append(tx)\n",
    "                        break  # Once we find a match, no need to check other logs for this transaction\n",
    "        \n",
    "        return filtered\n",
    "\n",
    "    def print_cached_transactions(self):\n",
    "        \"\"\"\n",
    "        Print all cached transactions in memory.\n",
    "        \"\"\"\n",
    "        if not self.cache:\n",
    "            print(\"No transactions in cache.\")\n",
    "        else:\n",
    "            for block_number, transactions in self.cache.items():\n",
    "                print(f\"Block Number: {block_number}\")\n",
    "                print(\"Transactions:\")\n",
    "                for tx in transactions:\n",
    "                    print(tx)  # You can adjust the output format as needed\n",
    "                print(\"-\" * 80)\n",
    "                \n",
    "    def aggregate_cache_to_csv(self, filename=\"aggregated_transactions.csv\"):\n",
    "        \"\"\"\n",
    "        Aggregate all transactions in cache and write them to a CSV file.\n",
    "        This flattens the nested JSON structure into a CSV format.\n",
    "        \"\"\"\n",
    "        all_transactions = []\n",
    "        \n",
    "        # Iterate over all transactions in the cache\n",
    "        for block_number, transactions in self.cache.items():\n",
    "            for tx in transactions:\n",
    "                flattened_tx = self.flatten_transaction(tx, block_number)\n",
    "                all_transactions.append(flattened_tx)\n",
    "\n",
    "        # Write the aggregated data to a CSV file\n",
    "        if all_transactions:\n",
    "            with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.DictWriter(file, fieldnames=all_transactions[0].keys())\n",
    "                writer.writeheader()\n",
    "                writer.writerows(all_transactions)\n",
    "            print(f\"CSV file '{filename}' has been created successfully.\")\n",
    "        else:\n",
    "            print(\"No transactions to write to CSV.\")\n",
    "\n",
    "    def flatten_transaction(self, tx, block_number):\n",
    "        \"\"\"\n",
    "        Flatten the nested transaction structure into a flat dictionary that can be written to CSV.\n",
    "        This method has been modified to match the functionality in the `process_logs` function.\n",
    "        \"\"\"\n",
    "        flattened = {\n",
    "            \"transaction_id\": tx.get(\"id\"),  # tx_id\n",
    "            \"contract_address\": tx.get(\"contract_address\"),\n",
    "            \"block_number\": block_number,\n",
    "            \"block_timestamp\": datetime.utcfromtimestamp(tx.get(\"blockTimeStamp\") / 1000) if tx.get(\"blockTimeStamp\") else None,\n",
    "            #\"contract_result\": tx.get(\"contractResult\"),\n",
    "            \"receipt_result\": tx.get(\"receipt\", {}).get(\"result\"),\n",
    "            #\"energy_usage\": tx.get(\"receipt\", {}).get(\"energy_usage\"),\n",
    "            #\"net_usage\": tx.get(\"receipt\", {}).get(\"net_usage\"),\n",
    "        }\n",
    "        \n",
    "        # Process logs to determine event types\n",
    "        logs = tx.get(\"log\", [])\n",
    "        for i, log in enumerate(logs):\n",
    "            event_type = None\n",
    "            tron_address = None\n",
    "\n",
    "            # Check the event type based on topic_0\n",
    "            topic_0 = log[\"topics\"][0] if log.get(\"topics\") else None\n",
    "            if topic_0 == ADDED_BLACKLIST_TOPIC:\n",
    "                event_type = \"AddedBlackList\"\n",
    "            elif topic_0 == REMOVED_BLACKLIST_TOPIC:\n",
    "                event_type = \"RemovedBlackList\"\n",
    "\n",
    "            # Only process logs for relevant events\n",
    "            if event_type:\n",
    "                if len(log.get(\"topics\", [])) > 1:\n",
    "                    topic_1 = log[\"topics\"][1]\n",
    "                    tron_address = hex_to_base58(hex_to_tron_address(topic_1))\n",
    "\n",
    "                # Adding processed logs details to flattened dict\n",
    "                flattened[\"event_type\"] = event_type\n",
    "                flattened[\"tron_address\"] = tron_address\n",
    "                #flattened[f\"log_{i}_contract_address\"] = log.get(\"address\")\n",
    "                #flattened[f\"log_{i}_block_timestamp\"] = flattened.get(\"block_timestamp\")\n",
    "\n",
    "        return flattened\n",
    "\n",
    "    \n",
    "    def clear_cache(self):\n",
    "            \"\"\"\n",
    "            Clears all data in the cache.\n",
    "            \"\"\"\n",
    "            self.cache.clear()\n",
    "            print(\"Cache has been cleared.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9d6063a5-2a46-4963-bfef-b9c8ba1fc7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cache instance\n",
    "cache = BlockTransactionCache()\n",
    "\n",
    "# Retrieve filtered transactions for block 57833080 (this will cache the result)\n",
    "filtered_transactions = cache.get_filtered_transactions(57833080)\n",
    "filtered_transactions = cache.get_filtered_transactions(57833084)\n",
    "# Retrieve filtered transactions again for the same block (this will use the cache)\n",
    "#filtered_transactions_again = cache.get_filtered_transactions(57833080)\n",
    "\n",
    "# Print the filtered transactions\n",
    "#print(filtered_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d63cc066-9610-472a-ae22-dcc6fbfbf6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block Number: 57833080\n",
      "Transactions:\n",
      "{'log': [{'address': '0fa695d6b065707cb4e0ef73b751c93347682bf2', 'topics': ['4a504a94899432a9846e1aa406dceb1bcfd538bb839071d49d1e5e23f5be30ef', '000000000000000000000000a89ae0805bbc6b0d7912d7103f216f3f2ff04f97', '0000000000000000000000000000000000000000000000000000000000000419']}, {'address': 'a614f803b6fd780986a42c78ec9c7f77e6ded13c', 'topics': ['42e160154868087d6bfdc0ca23d96a1c1cfa32f1b72ba9ba27b69b98a0d819dc', '000000000000000000000000c67d47af3dc61a89364f47bd00183c0700cf4ed3']}, {'address': '0fa695d6b065707cb4e0ef73b751c93347682bf2', 'topics': ['33e13ecb54c3076d8e8bb8c2881800a4d972b792045ffae98fdf46df365fed75', '0000000000000000000000000000000000000000000000000000000000000419']}], 'blockNumber': 57833080, 'contractResult': [''], 'blockTimeStamp': 1704132882000, 'receipt': {'result': 'SUCCESS', 'energy_penalty_total': 26102, 'energy_usage': 95895, 'energy_usage_total': 95895, 'net_usage': 313}, 'id': 'b3b38075f9987af64f56c7059f9adb1dd4233de2af36d2d60bf45d9e30446bc9', 'contract_address': '410fa695d6b065707cb4e0ef73b751c93347682bf2', 'internal_transactions': [{'caller_address': '410fa695d6b065707cb4e0ef73b751c93347682bf2', 'note': '63616c6c', 'transferTo_address': '41a614f803b6fd780986a42c78ec9c7f77e6ded13c', 'callValueInfo': [{}], 'hash': '470c634e035dd06b02d06725e3d2302f914af5b523ca5d327bab727b39a30100'}]}\n",
      "--------------------------------------------------------------------------------\n",
      "Block Number: 57833084\n",
      "Transactions:\n",
      "{'log': [{'address': '0fa695d6b065707cb4e0ef73b751c93347682bf2', 'topics': ['4a504a94899432a9846e1aa406dceb1bcfd538bb839071d49d1e5e23f5be30ef', '000000000000000000000000a89ae0805bbc6b0d7912d7103f216f3f2ff04f97', '000000000000000000000000000000000000000000000000000000000000041a']}, {'address': 'a614f803b6fd780986a42c78ec9c7f77e6ded13c', 'topics': ['42e160154868087d6bfdc0ca23d96a1c1cfa32f1b72ba9ba27b69b98a0d819dc', '000000000000000000000000c5445b28062f14318a01b416027672e6ef01bdb3']}, {'address': '0fa695d6b065707cb4e0ef73b751c93347682bf2', 'topics': ['33e13ecb54c3076d8e8bb8c2881800a4d972b792045ffae98fdf46df365fed75', '000000000000000000000000000000000000000000000000000000000000041a']}], 'blockNumber': 57833084, 'contractResult': [''], 'blockTimeStamp': 1704132894000, 'receipt': {'result': 'SUCCESS', 'energy_penalty_total': 26102, 'energy_usage': 95895, 'energy_usage_total': 95895, 'net_usage': 313}, 'id': '756a7eb2b9425ec8cee693105f07154eeac89d28d25b8b0b24aa26c5fa780b75', 'contract_address': '410fa695d6b065707cb4e0ef73b751c93347682bf2', 'internal_transactions': [{'caller_address': '410fa695d6b065707cb4e0ef73b751c93347682bf2', 'note': '63616c6c', 'transferTo_address': '41a614f803b6fd780986a42c78ec9c7f77e6ded13c', 'callValueInfo': [{}], 'hash': '3817bfa13ba969bc7c70eac07fd9ee80ad8391296022f304248e6856cb21cdb7'}]}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cache.print_cached_transactions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "30811b5b-8a52-4059-8a88-2b180056fbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:23<00:00,  4.19it/s]\n"
     ]
    }
   ],
   "source": [
    "block_last=57833080\n",
    "offset = 100\n",
    "\n",
    "cache = BlockTransactionCache()\n",
    "\n",
    "for block_number in tqdm(range(block_last, block_last+offset)):\n",
    "    cache.get_filtered_transactions(block_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376f7d2a-6e84-40cf-83bc-a033e9d82c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6a39b739-6242-4dba-bd46-ae129350a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cache.print_cached_transactions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8ab0e232-8d3b-41fe-822b-0dba1e29a40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'aggregated_transactions.csv' has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "cache.aggregate_cache_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2f0225c0-bae4-426b-aa72-220e9f4d1cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache has been cleared.\n"
     ]
    }
   ],
   "source": [
    "cache.clear_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ba0e9e3e-2828-4071-90ff-1a383c2c6b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions in cache.\n"
     ]
    }
   ],
   "source": [
    "cache.print_cached_transactions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "72e74d9f-69ee-4fed-80f3-13d4fde0e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конфігурація для багатопотокової обробки\n",
    "batch_size = 100  # наприклад, розмір пачки\n",
    "offset = 0  # початковий зсув\n",
    "max_workers = 3  # кількість потоків"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "81766204-c625-482c-9115-0a305fd84467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal max_workers: 24\n"
     ]
    }
   ],
   "source": [
    "# Get the number of logical CPU cores\n",
    "num_cores = os.cpu_count()\n",
    "\n",
    "# Get available memory in MB\n",
    "available_memory = psutil.virtual_memory().available / (1024 * 1024)\n",
    "\n",
    "# Estimate the memory usage per thread (in MB)\n",
    "memory_per_thread = 100  # Adjust based on your task's requirements\n",
    "# Calculate max workers based on memory\n",
    "max_workers_memory = int(available_memory // memory_per_thread)\n",
    "\n",
    "# Choose the smaller value between CPU-bound and memory-bound limits\n",
    "max_workers = min(num_cores * 2, max_workers_memory)  # Assuming I/O-bound tasks\n",
    "print(f\"Optimal max_workers: {max_workers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e486d83-6a1f-465a-8125-5d6183d1e4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = BlockTransactionCache()\n",
    "\n",
    "batch_size = 100\n",
    "block_last = 57833080\n",
    "\n",
    "while block_last < 57834080: #69200000:\n",
    "    \n",
    "    cache.get_filtered_transactions(block_last)\n",
    "    process_batch(block_last, batch_size)\n",
    "    block_last =  block_last + batch_size\n",
    "    delete_files_with_prefix(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "24838058-df68-44dc-970d-6c907f3852d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(cache, block_last, batch_size):\n",
    "    \n",
    "        # Process blocks in parallel using ThreadPoolExecutor\n",
    "        block_last = block_last  # Adjust to your starting block\n",
    "        block_numbers = range(block_last, block_last + batch_size)  # Adjust the range of blocks you want to process\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_block = {executor.submit(cache.get_filtered_transactions, block_number): block_number for block_number in block_numbers}\n",
    "\n",
    "            # Track progress with tqdm for parallel tasks\n",
    "            for future in tqdm(as_completed(future_to_block), total=len(block_numbers), desc=\"Processing blocks\", unit=\"block\"):\n",
    "                block_number = future_to_block[future]\n",
    "                try:\n",
    "                    future.result()  # Wait for the block processing to finish\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "                    #print(f\"Block {block_number} generated an error: {e}\")\n",
    "                    \n",
    "        #aggregate_and_cleanup_csvs(f\"aggregated_transactions-{block_last}.csv\", prefix=\"logs_block\")\n",
    "        cache.aggregate_cache_to_csv(filename=f\"aggregated_transactions-{block_last}.csv\")\n",
    "        cache.clear_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e386e395-3fd2-4f7e-b492-018091c22dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:14<00:00, 133.41block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:12<00:00, 138.37block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:22<00:00, 121.65block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:16<00:00, 130.38block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:13<00:00, 136.79block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:22<00:00, 121.14block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:15<00:00, 132.28block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:15<00:00, 131.92block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:22<00:00, 120.57block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:15<00:00, 133.12block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:17<00:00, 129.60block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:23<00:00, 119.35block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:13<00:00, 136.83block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:18<00:00, 127.53block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:22<00:00, 120.85block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:12<00:00, 137.10block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'aggregated_transactions-58150000.csv' has been created successfully.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:17<00:00, 128.96block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:19<00:00, 125.93block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:10<00:00, 140.92block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:17<00:00, 128.89block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:18<00:00, 127.99block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:11<00:00, 139.10block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:21<00:00, 122.52block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:19<00:00, 125.25block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:11<00:00, 139.21block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:21<00:00, 122.39block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:17<00:00, 129.23block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:12<00:00, 138.11block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:22<00:00, 120.90block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:16<00:00, 131.58block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:16<00:00, 131.33block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:21<00:00, 122.57block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:15<00:00, 132.83block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:16<00:00, 130.29block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:23<00:00, 119.36block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:13<00:00, 136.76block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:16<00:00, 131.21block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:20<00:00, 124.88block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:11<00:00, 139.78block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:16<00:00, 131.25block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:19<00:00, 126.51block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:11<00:00, 140.23block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:20<00:00, 124.06block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:22<00:00, 121.87block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'aggregated_transactions-58430000.csv' has been created successfully.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:12<00:00, 137.79block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:22<00:00, 120.74block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:20<00:00, 124.60block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:13<00:00, 136.96block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:21<00:00, 121.99block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 10000/10000 [01:18<00:00, 127.19block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transactions to write to CSV.\n",
      "Cache has been cleared.\n"
     ]
    }
   ],
   "source": [
    "cache = BlockTransactionCache()\n",
    "\n",
    "batch_size = 10000\n",
    "block_last = 58000000#57833080\n",
    "\n",
    "while block_last < 58500000:#58000000: #69200000:\n",
    "\n",
    "    process_batch(cache, block_last, batch_size)\n",
    "    block_last =  block_last + batch_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
